# Bank Customer Churn Demo

This repo contains a complete end-to-end demo for teaching supervised machine learning with **Greenplum Database + MADlib** using the [Kaggle Bank Customer Churn dataset](https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn).

The goal is to show how to:
- Load real-world data into Greenplum
- Prepare training and test splits
- Train a decision tree classifier
- Generate predictions
- Validate model accuracy with a confusion matrix and standard metrics

NOTE: This demo was bootstrapped using **gpmlbot**, which generated the SQL scripts quickly and recommended the best model families for the churn prediction use case. From there, I refined the workflow (splitting, training, validation, and evaluation) into a clear teaching example

## Repository Structure
bankchurn/
├── README.md              # This file
├── bankchurn_schema.sql   # Schema definition for churn tables
├── load.sql               # COPY command to load Kaggle CSV into Greenplum
├── train_decisiontree.sql # MADlib decision tree training and prediction
└── final_validation.sql   # Accuracy evaluation and confusion matrix

## Key Tables
- **`bank_customer_churn`** – Raw dataset loaded from Kaggle  
- **`churn_train` / `churn_validate`** – 80/20 training & validation splits  
- **`churn_model`** – Trained decision tree model  
- **`churn_model_summary`** – Model metadata and training statistics  
- **`churn_predictions`** – Predictions generated by the model  
- **`churn_predictions_all`** – Predictions across the full dataset (optional)  

## Metrics

The validation step produces:
- Confusion Matrix (TP, TN, FP, FN)  
- Accuracy  
- Precision  

## Prerequisites

- Greenplum Database 7+  
- MADlib extension installed  
- PostgresML extension installed


## . Create the schema
psql -d banks -f bankchurn_schema.sql

## . Load the data
psql -d banks -f load.sql

## . Train the model
psql -d banks -f train_decisiontree.sql

## . Validate the model
psql -d banks -f final_validation.sql

